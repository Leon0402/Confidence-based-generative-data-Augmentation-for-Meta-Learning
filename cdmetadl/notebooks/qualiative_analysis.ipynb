{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import cdmetadl\n",
    "\n",
    "PROJECT_DIR = pathlib.Path(cdmetadl.__file__).parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdmetadl.samplers\n",
    "import cdmetadl.helpers.general_helpers\n",
    "import cdmetadl.dataset\n",
    "\n",
    "path_to_dataset = \"/fastdata/vilab24/meta-album\"\n",
    "dataset_path = pathlib.Path(path_to_dataset)\n",
    "dataset_info_dict = cdmetadl.helpers.general_helpers.check_datasets(dataset_path, [\"BTS\"])\n",
    "dataset = cdmetadl.dataset.ImageDataset(\"Boats\", dataset_info_dict[\"BTS\"])\n",
    "\n",
    "n_way_sampler = cdmetadl.samplers.ValueSampler(value=5)\n",
    "k_shot_sampler = cdmetadl.samplers.ValueSampler(value=21)\n",
    "task = dataset.generate_task(n_way_sampler, k_shot_sampler, query_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    }
   ],
   "source": [
    "import cdmetadl.helpers.general_helpers\n",
    "import cdmetadl.api\n",
    "import cdmetadl.confidence\n",
    "import cdmetadl.augmentation\n",
    "import cdmetadl.helpers.scoring_helpers\n",
    "\n",
    "model_name = \"finetuning\"\n",
    "model_dir = f\"/fastdata/vilab24/output/final/training/dropout_30_k_1/{model_name}/cross-domain/model\"\n",
    "\n",
    "device = cdmetadl.helpers.general_helpers.get_device()\n",
    "\n",
    "model_module = cdmetadl.helpers.general_helpers.load_module_from_path(PROJECT_DIR / f\"./baselines/{model_name}/model.py\")\n",
    "confidence_learner: cdmetadl.api.Learner = model_module.MyLearner()\n",
    "learner: cdmetadl.api.Learner = model_module.MyLearner()\n",
    "\n",
    "confidence_estimator = cdmetadl.confidence.PseudoConfidenceEstimator()\n",
    "augmentor = cdmetadl.augmentation.PseudoAugmentation(augmentation_size={\n",
    "    \"scale\": 1,\n",
    "    \"offset\": 3 ,\n",
    "    \"maximum\": 20,\n",
    "    \"threshold\": 0.8,\n",
    "},\n",
    "keep_original_data=True, device=device)\n",
    "\n",
    "task.support_set.images = task.support_set.images.to(device)\n",
    "task.support_set.labels = task.support_set.labels.to(device)\n",
    "task.query_set.images = task.query_set.images.to(device)\n",
    "task.query_set.labels = task.query_set.labels.to(device)\n",
    "\n",
    "original_number_of_shots = task.support_set.min_number_of_shots\n",
    "\n",
    "confidence_learner.load(model_dir)\n",
    "# Adjust T for finetuning\n",
    "confidence_learner.T = 1000\n",
    "support_set, confidence_scores = confidence_estimator.estimate(confidence_learner, task.support_set)\n",
    "\n",
    "support_set_without_confidence = support_set\n",
    "\n",
    "learner.load(model_dir)\n",
    "# Adjust T for finetuning\n",
    "learner.T = 1000\n",
    "predictor = learner.fit(task.support_set)\n",
    "\n",
    "pred_dict_prev = {\n",
    "    \"Dataset\": task.dataset_name,\n",
    "    \"Number of Ways\": task.number_of_ways,\n",
    "    \"Number of Shots\": original_number_of_shots,\n",
    "    \"Number of Shots per Class\": support_set.number_of_shots_per_class,\n",
    "    \"Confidence Scores\": confidence_scores,\n",
    "    \"Predictions\": predictor.predict(task.query_set.images).cpu().numpy(),\n",
    "    \"Ground Truth\": task.query_set.labels.cpu().numpy(),\n",
    "}\n",
    "\n",
    "scores_prev = cdmetadl.helpers.scoring_helpers.compute_all_scores(\n",
    "    pred_dict_prev[\"Ground Truth\"], pred_dict_prev[\"Predictions\"], pred_dict_prev[\"Number of Ways\"]\n",
    ")\n",
    "\n",
    "if augmentor is not None:\n",
    "    # print(confidence_scores)\n",
    "    support_set = augmentor.augment(support_set, conf_scores=confidence_scores)\n",
    "\n",
    "learner.load(model_dir)\n",
    "# Adjust T for finetuning\n",
    "learner.T = 1000\n",
    "predictor = learner.fit(support_set)\n",
    "\n",
    "pred_dict = {\n",
    "    \"Dataset\": task.dataset_name,\n",
    "    \"Number of Ways\": task.number_of_ways,\n",
    "    \"Number of Shots\": original_number_of_shots,\n",
    "    \"Number of Shots per Class\": support_set.number_of_shots_per_class,\n",
    "    \"Confidence Scores\": confidence_scores,\n",
    "    \"Predictions\": predictor.predict(task.query_set.images).cpu().numpy(),\n",
    "    \"Ground Truth\": task.query_set.labels.cpu().numpy(),\n",
    "}\n",
    "\n",
    "scores = cdmetadl.helpers.scoring_helpers.compute_all_scores(\n",
    "    pred_dict[\"Ground Truth\"], pred_dict[\"Predictions\"], pred_dict[\"Number of Ways\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04358408153057099,\n",
       " 0.21569089889526366,\n",
       " 0.1704721122980118,\n",
       " 0.22646460235118865,\n",
       " 0.08967948853969573]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "confidence_learner.load(model_dir)\n",
    "# Adjust T for finetuning\n",
    "confidence_learner.T = 1000\n",
    "\n",
    "predictor = confidence_learner.fit(support_set_without_confidence)\n",
    "\n",
    "confidence_scores = defaultdict(list)\n",
    "for prediction, gt_label in zip(predictor.predict(task.query_set.images).cpu().numpy(), task.query_set.labels):\n",
    "    gt_label = int(gt_label)\n",
    "\n",
    "    confidence_score = 0.0\n",
    "    if np.argmax(prediction) == gt_label:\n",
    "        confidence_score = np.max(prediction)\n",
    "\n",
    "    confidence_scores[gt_label].append(confidence_score)\n",
    "\n",
    "[np.mean(scores) for scores in confidence_scores.values()]\n",
    "\n",
    "# [0.06470633745193481, 0.08580020368099213, 0.5084564238786697, 0.1895177721977234, 0.032207930088043214]\n",
    "# [0.61396587, 0.5356838136911393, 0.87390435, 0.74509877, 0.6357733845710755]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Accuracy    0.175000\n",
      "Accuracy               0.340000\n",
      "Macro F1 Score         0.288329\n",
      "Macro Precision        0.269398\n",
      "Macro Recall           0.340000\n",
      "dtype: float64\n",
      "[0.06470633745193481, 0.08580020368099213, 0.5084564238786697, 0.1895177721977234, 0.032207930088043214]\n",
      "[5 5 2 4 5]\n",
      "Normalized Accuracy    0.175000\n",
      "Accuracy               0.340000\n",
      "Macro F1 Score         0.352974\n",
      "Macro Precision        0.393086\n",
      "Macro Recall           0.340000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(pd.Series(scores_prev))\n",
    "print(pred_dict[\"Confidence Scores\"])\n",
    "print(pred_dict[\"Number of Shots per Class\"])\n",
    "print(pd.Series(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    }
   ],
   "source": [
    "import cdmetadl.helpers.general_helpers\n",
    "import cdmetadl.api\n",
    "import cdmetadl.confidence\n",
    "import cdmetadl.augmentation\n",
    "import cdmetadl.helpers.scoring_helpers\n",
    "\n",
    "model_name = \"finetuning\"\n",
    "model_dir = f\"/fastdata/vilab24/output/final/training/dropout_30_k_1/{model_name}/cross-domain/model\"\n",
    "\n",
    "device = cdmetadl.helpers.general_helpers.get_device()\n",
    "\n",
    "model_module = cdmetadl.helpers.general_helpers.load_module_from_path(\n",
    "    PROJECT_DIR / f\"./baselines/{model_name}/model.py\"\n",
    ")\n",
    "confidence_learner: cdmetadl.api.Learner = model_module.MyLearner()\n",
    "learner: cdmetadl.api.Learner = model_module.MyLearner()\n",
    "\n",
    "confidence_estimator = cdmetadl.confidence.ConstantConfidenceProvider(confidence=0.20)\n",
    "augmentor = cdmetadl.augmentation.PseudoAugmentation(\n",
    "    augmentation_size={\n",
    "        \"scale\": 1,\n",
    "        \"offset\": 3,\n",
    "        \"maximum\": 20,\n",
    "        \"threshold\": 0.8,\n",
    "    }, keep_original_data=True, device=device\n",
    ")\n",
    "\n",
    "task.support_set.images = task.support_set.images.to(device)\n",
    "task.support_set.labels = task.support_set.labels.to(device)\n",
    "task.query_set.images = task.query_set.images.to(device)\n",
    "task.query_set.labels = task.query_set.labels.to(device)\n",
    "\n",
    "original_number_of_shots = task.support_set.min_number_of_shots\n",
    "\n",
    "confidence_learner.load(model_dir)\n",
    "# Adjust T for finetuning\n",
    "confidence_learner.T = 1000\n",
    "support_set, confidence_scores = confidence_estimator.estimate(confidence_learner, support_set_without_confidence)\n",
    "\n",
    "learner.load(model_dir)\n",
    "# Adjust T for finetuning\n",
    "learner.T = 1000\n",
    "predictor = learner.fit(task.support_set)\n",
    "\n",
    "pred_dict_prev_all = {\n",
    "    \"Dataset\": task.dataset_name,\n",
    "    \"Number of Ways\": task.number_of_ways,\n",
    "    \"Number of Shots\": original_number_of_shots,\n",
    "    \"Number of Shots per Class\": support_set.number_of_shots_per_class,\n",
    "    \"Confidence Scores\": confidence_scores,\n",
    "    \"Predictions\": predictor.predict(task.query_set.images).cpu().numpy(),\n",
    "    \"Ground Truth\": task.query_set.labels.cpu().numpy(),\n",
    "}\n",
    "\n",
    "scores_prev_all = cdmetadl.helpers.scoring_helpers.compute_all_scores(\n",
    "    pred_dict_prev_all[\"Ground Truth\"], pred_dict_prev_all[\"Predictions\"], pred_dict_prev_all[\"Number of Ways\"]\n",
    ")\n",
    "\n",
    "if augmentor is not None:\n",
    "    # print(confidence_scores)\n",
    "    support_set = augmentor.augment(support_set, conf_scores=confidence_scores)\n",
    "\n",
    "learner.load(model_dir)\n",
    "# Adjust T for finetuning\n",
    "learner.T = 1000\n",
    "predictor = learner.fit(support_set)\n",
    "\n",
    "pred_dict_all = {\n",
    "    \"Dataset\": task.dataset_name,\n",
    "    \"Number of Ways\": task.number_of_ways,\n",
    "    \"Number of Shots\": original_number_of_shots,\n",
    "    \"Number of Shots per Class\": support_set.number_of_shots_per_class,\n",
    "    \"Confidence Scores\": confidence_scores,\n",
    "    \"Predictions\": predictor.predict(task.query_set.images).cpu().numpy(),\n",
    "    \"Ground Truth\": task.query_set.labels.cpu().numpy(),\n",
    "}\n",
    "\n",
    "scores_all = cdmetadl.helpers.scoring_helpers.compute_all_scores(\n",
    "    pred_dict_all[\"Ground Truth\"], pred_dict_all[\"Predictions\"], pred_dict_all[\"Number of Ways\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Accuracy    0.175000\n",
      "Accuracy               0.340000\n",
      "Macro F1 Score         0.320000\n",
      "Macro Precision        0.347255\n",
      "Macro Recall           0.340000\n",
      "dtype: float64\n",
      "[0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "[4 4 4 4 4]\n",
      "Normalized Accuracy    0.275000\n",
      "Accuracy               0.420000\n",
      "Macro F1 Score         0.399434\n",
      "Macro Precision        0.456224\n",
      "Macro Recall           0.420000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(scores_prev_all))\n",
    "print(pred_dict_all[\"Confidence Scores\"])\n",
    "print(pred_dict_all[\"Number of Shots per Class\"])\n",
    "print(pd.Series(scores_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    }
   ],
   "source": [
    "import cdmetadl.helpers.general_helpers\n",
    "import cdmetadl.api\n",
    "import cdmetadl.confidence\n",
    "import cdmetadl.augmentation\n",
    "import cdmetadl.helpers.scoring_helpers\n",
    "\n",
    "model_name = \"finetuning\"\n",
    "model_dir = f\"/fastdata/vilab24/output/final/training/dropout_30_k_1/{model_name}/cross-domain/model\"\n",
    "\n",
    "device = cdmetadl.helpers.general_helpers.get_device()\n",
    "\n",
    "model_module = cdmetadl.helpers.general_helpers.load_module_from_path(\n",
    "    PROJECT_DIR / f\"./baselines/{model_name}/model.py\"\n",
    ")\n",
    "confidence_learner: cdmetadl.api.Learner = model_module.MyLearner()\n",
    "learner: cdmetadl.api.Learner = model_module.MyLearner()\n",
    "\n",
    "confidence_estimator = cdmetadl.confidence.ConstantConfidenceProvider(confidence=0.20)\n",
    "augmentor = cdmetadl.augmentation.PseudoAugmentation(\n",
    "    augmentation_size={\n",
    "        \"scale\": 1,\n",
    "        \"offset\": 3,\n",
    "        \"maximum\": 20,\n",
    "        \"threshold\": 0.8,\n",
    "    }, keep_original_data=True, device=device\n",
    ")\n",
    "\n",
    "task.support_set.images = task.support_set.images.to(device)\n",
    "task.support_set.labels = task.support_set.labels.to(device)\n",
    "task.query_set.images = task.query_set.images.to(device)\n",
    "task.query_set.labels = task.query_set.labels.to(device)\n",
    "\n",
    "original_number_of_shots = task.support_set.min_number_of_shots\n",
    "\n",
    "confidence_learner.load(model_dir)\n",
    "# Adjust T for finetuning\n",
    "confidence_learner.T = 1000\n",
    "support_set = support_set_without_confidence\n",
    "\n",
    "\n",
    "learner.load(model_dir)\n",
    "# Adjust T for finetuning\n",
    "learner.T = 1000\n",
    "predictor = learner.fit(task.support_set)\n",
    "\n",
    "predictions = predictor.predict(task.query_set.images).cpu().numpy()\n",
    "\n",
    "confidence_scores = defaultdict(list)\n",
    "for prediction, gt_label in zip(predictions, task.query_set.labels):\n",
    "    gt_label = int(gt_label)\n",
    "\n",
    "    confidence_score = 0.0\n",
    "    if np.argmax(prediction) == gt_label:\n",
    "        confidence_score = np.max(prediction)\n",
    "\n",
    "    confidence_scores[gt_label].append(confidence_score)\n",
    "\n",
    "confidence_scores = [np.mean(scores) for scores in confidence_scores.values()]\n",
    "\n",
    "pred_dict_prev_all = {\n",
    "    \"Dataset\": task.dataset_name,\n",
    "    \"Number of Ways\": task.number_of_ways,\n",
    "    \"Number of Shots\": original_number_of_shots,\n",
    "    \"Number of Shots per Class\": support_set.number_of_shots_per_class,\n",
    "    \"Confidence Scores\": confidence_scores,\n",
    "    \"Predictions\": predictions,\n",
    "    \"Ground Truth\": task.query_set.labels.cpu().numpy(),\n",
    "}\n",
    "\n",
    "\n",
    "scores_prev_all = cdmetadl.helpers.scoring_helpers.compute_all_scores(\n",
    "    pred_dict_prev_all[\"Ground Truth\"], pred_dict_prev_all[\"Predictions\"], pred_dict_prev_all[\"Number of Ways\"]\n",
    ")\n",
    "\n",
    "if augmentor is not None:\n",
    "    # print(confidence_scores)\n",
    "    support_set = augmentor.augment(support_set, conf_scores=confidence_scores)\n",
    "\n",
    "learner.load(model_dir)\n",
    "# Adjust T for finetuning\n",
    "learner.T = 1000\n",
    "predictor = learner.fit(support_set)\n",
    "\n",
    "pred_dict_all = {\n",
    "    \"Dataset\": task.dataset_name,\n",
    "    \"Number of Ways\": task.number_of_ways,\n",
    "    \"Number of Shots\": original_number_of_shots,\n",
    "    \"Number of Shots per Class\": support_set.number_of_shots_per_class,\n",
    "    \"Confidence Scores\": confidence_scores,\n",
    "    \"Predictions\": predictor.predict(task.query_set.images).cpu().numpy(),\n",
    "    \"Ground Truth\": task.query_set.labels.cpu().numpy(),\n",
    "}\n",
    "\n",
    "scores_all = cdmetadl.helpers.scoring_helpers.compute_all_scores(\n",
    "    pred_dict_all[\"Ground Truth\"], pred_dict_all[\"Predictions\"], pred_dict_all[\"Number of Ways\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Accuracy    0.175000\n",
      "Accuracy               0.340000\n",
      "Macro F1 Score         0.320000\n",
      "Macro Precision        0.347255\n",
      "Macro Recall           0.340000\n",
      "dtype: float64\n",
      "[0.13608461618423462, 0.31828450262546537, 0.23118655383586884, 0.15830894708633422, 0.02658001482486725]\n",
      "[4 3 4 4 5]\n",
      "Normalized Accuracy    0.250000\n",
      "Accuracy               0.400000\n",
      "Macro F1 Score         0.392721\n",
      "Macro Precision        0.492794\n",
      "Macro Recall           0.400000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(scores_prev_all))\n",
    "print(pred_dict_all[\"Confidence Scores\"])\n",
    "print(pred_dict_all[\"Number of Shots per Class\"])\n",
    "print(pd.Series(scores_all))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cd-metadl-OKmTAZk1-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
