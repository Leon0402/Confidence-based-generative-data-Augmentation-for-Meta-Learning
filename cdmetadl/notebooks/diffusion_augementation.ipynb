{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset = \"../../public_data\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import cdmetadl.helpers.general_helpers\n",
    "import cdmetadl.dataset\n",
    "\n",
    "dataset_path = pathlib.Path(path_to_dataset)\n",
    "dataset_info_dict = cdmetadl.helpers.general_helpers.check_datasets(dataset_path, [\"APL\"])\n",
    "\n",
    "dataset = cdmetadl.dataset.ImageDataset(\"Airplanes\", dataset_info_dict[\"APL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdmetadl.samplers\n",
    "\n",
    "n_way_sampler = cdmetadl.samplers.ValueSampler(value=5)\n",
    "k_shot_sampler = cdmetadl.samplers.ValueSampler(value=4)\n",
    "\n",
    "task = dataset.generate_task(n_way_sampler, k_shot_sampler, query_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdmetadl.augmentation\n",
    "import cdmetadl.notebooks.helpers\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(augmentor, task):\n",
    "    augmented_set_generative = augmentor.augment(task.support_set, conf_scores=[0.1, 0.1, 0.1, 0.1, 0.1])\n",
    "\n",
    "    fig = cdmetadl.notebooks.helpers.show_images_grid_plotly(task.support_set)\n",
    "    fig.update_layout(title='Original data')\n",
    "    fig.show()\n",
    "    fig = cdmetadl.notebooks.helpers.show_images_grid_plotly(augmented_set_generative)\n",
    "    fig.update_layout(title='Generative Augmented data')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canny Edge Detection + ControlNet Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_augmentor = cdmetadl.augmentation.GenerativeAugmentation(threshold=0.75, scale=1.0,\n",
    "                                                                        keep_original_data=False)\n",
    "\n",
    "def edge_detection(self, image):\n",
    "    image = np.array(image) #512x512x3\n",
    "    low_threshold = 100\n",
    "    high_threshold = 200\n",
    "\n",
    "    canny_image = cv2.Canny(image, low_threshold, high_threshold) #512x512\n",
    "    canny_image = canny_image[:, :, None] #512x512x1\n",
    "    canny_image = np.concatenate([canny_image, canny_image, canny_image], axis=2) #512x512x3\n",
    "    canny_image = Image.fromarray(canny_image)\n",
    "\n",
    "    return canny_image\n",
    "\n",
    "cdmetadl.augmentation.GenerativeAugmentation.edge_detection = edge_detection\n",
    "\n",
    "generative_augmentor = cdmetadl.augmentation.GenerativeAugmentation(threshold=0.75, scale=1.0,\n",
    "                                                                    diffusion_model_id=\"lllyasviel/sd-controlnet-canny\",\n",
    "                                                                        keep_original_data=False)\n",
    "\n",
    "create_plot(generative_augmentor, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation Edge Detection + ControlNet Seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdmetadl.annotator.uniformer import UniformerDetector\n",
    "\n",
    "apply_uniformer = UniformerDetector()\n",
    "\n",
    "def edge_detection(self, image):\n",
    "        with torch.no_grad():\n",
    "                image = np.array(image)\n",
    "                detected_map = apply_uniformer(image)\n",
    "        return Image.fromarray(detected_map)\n",
    "\n",
    "\n",
    "cdmetadl.augmentation.GenerativeAugmentation.edge_detection = edge_detection\n",
    "\n",
    "generative_augmentor = cdmetadl.augmentation.GenerativeAugmentation(threshold=0.75, scale=1.0,\n",
    "                                                                    diffusion_model_id=\"lllyasviel/sd-controlnet-seg\",\n",
    "                                                                        keep_original_data=False)\n",
    "\n",
    "\n",
    "create_plot(generative_augmentor, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HED Boundaries+ ControlNet HED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdmetadl.annotator.hed import HEDdetector\n",
    "\n",
    "apply_hed = HEDdetector()\n",
    "\n",
    "def edge_detection(self, image):\n",
    "        with torch.no_grad():\n",
    "                image = np.array(image)\n",
    "                detected_map = apply_hed(image)\n",
    "        return Image.fromarray(detected_map)\n",
    "\n",
    "\n",
    "cdmetadl.augmentation.GenerativeAugmentation.edge_detection = edge_detection\n",
    "\n",
    "generative_augmentor = cdmetadl.augmentation.GenerativeAugmentation(threshold=0.75, scale=1.0,\n",
    "                                                                    diffusion_model_id=\"lllyasviel/sd-controlnet-hed\",\n",
    "                                                                        keep_original_data=False)\n",
    "\n",
    "\n",
    "create_plot(generative_augmentor, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M-LSD Lines + ControlNet M-LSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdmetadl.annotator.mlsd import MLSDdetector\n",
    "\n",
    "apply_mlsd = MLSDdetector()\n",
    "\n",
    "def edge_detection(self, image):\n",
    "        with torch.no_grad():\n",
    "                value_threshold = 0.1\n",
    "                distance_threshold = 0.1\n",
    "                image = np.array(image)\n",
    "                detected_map = apply_mlsd(image, value_threshold, distance_threshold)\n",
    "        return Image.fromarray(detected_map)\n",
    "\n",
    "\n",
    "cdmetadl.augmentation.GenerativeAugmentation.edge_detection = edge_detection\n",
    "\n",
    "generative_augmentor = cdmetadl.augmentation.GenerativeAugmentation(threshold=0.75, scale=1.0,\n",
    "                                                                    diffusion_model_id=\"lllyasviel/sd-controlnet-mlsd\",\n",
    "                                                                        keep_original_data=False)\n",
    "\n",
    "\n",
    "create_plot(generative_augmentor, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midas Depth Maps + ControlNet Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdmetadl.annotator.midas import MidasDetector\n",
    "\n",
    "apply_midas = MidasDetector()\n",
    "\n",
    "def edge_detection(self, image):\n",
    "        with torch.no_grad():\n",
    "                image = np.array(image)\n",
    "                detected_map = apply_midas(image)\n",
    "        \n",
    "        return Image.fromarray(detected_map[1])\n",
    "\n",
    "\n",
    "cdmetadl.augmentation.GenerativeAugmentation.edge_detection = edge_detection\n",
    "\n",
    "generative_augmentor = cdmetadl.augmentation.GenerativeAugmentation(threshold=0.75, scale=1.0,\n",
    "                                                                    diffusion_model_id=\"lllyasviel/sd-controlnet-depth\",\n",
    "                                                                        keep_original_data=False)\n",
    "\n",
    "create_plot(generative_augmentor, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midas Depth Maps + ControlNet Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdmetadl.annotator.midas import MidasDetector\n",
    "\n",
    "apply_midas = MidasDetector()\n",
    "\n",
    "def edge_detection(self, image):\n",
    "        with torch.no_grad():\n",
    "                image = np.array(image)\n",
    "                detected_map = apply_midas(image)\n",
    "        \n",
    "        return Image.fromarray(detected_map[1])\n",
    "\n",
    "\n",
    "cdmetadl.augmentation.GenerativeAugmentation.edge_detection = edge_detection\n",
    "\n",
    "\n",
    "generative_augmentor = cdmetadl.augmentation.GenerativeAugmentation(threshold=0.75, scale=1.0,\n",
    "                                                                    diffusion_model_id=\"lllyasviel/sd-controlnet-normal\",\n",
    "                                                                        keep_original_data=False)\n",
    "\n",
    "\n",
    "create_plot(generative_augmentor, task)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
