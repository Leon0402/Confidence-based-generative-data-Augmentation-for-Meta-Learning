{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import cdmetadl\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cdmetadl.helpers.general_helpers\n",
    "import cdmetadl.dataset\n",
    "import cdmetadl.samplers\n",
    "import cdmetadl.confidence\n",
    "import cdmetadl.notebooks.helpers\n",
    "path_to_dataset = \"/fastdata/vilab24/meta-album\"\n",
    "\n",
    "\n",
    "PROJECT_DIR = pathlib.Path(cdmetadl.__file__).parent.parent\n",
    "\n",
    "\n",
    "dataset_path = pathlib.Path(path_to_dataset)\n",
    "dataset_info_dict = cdmetadl.helpers.general_helpers.check_datasets(dataset_path, [\"AWA\"])\n",
    "\n",
    "dataset = cdmetadl.dataset.ImageDataset(\"-\", dataset_info_dict[\"AWA\"])\n",
    "\n",
    "\n",
    "n_way_sampler = cdmetadl.samplers.ValueSampler(value=5)\n",
    "k_shot_sampler = cdmetadl.samplers.ValueSampler(value=4)\n",
    "\n",
    "task = dataset.generate_task(n_way_sampler, k_shot_sampler, query_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Dropout Confidence Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:25<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: 1, Average Correlation between runs: -0.0842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: 10, Average Correlation between runs: 0.0406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:27<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: 50, Average Correlation between runs: 0.4055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:30<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: 100, Average Correlation between runs: 0.6277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:40<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: 250, Average Correlation between runs: 0.3957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:48<00:00,  4.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: 500, Average Correlation between runs: 0.9529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:58<00:00,  5.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: 750, Average Correlation between runs: 0.9914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:06<00:00,  6.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: 1000, Average Correlation between runs: 0.9935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:26<00:00,  8.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: 1500, Average Correlation between runs: 0.9952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:45<00:00, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: 2000, Average Correlation between runs: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "confidence_estimator = cdmetadl.confidence.MCDropoutConfidenceEstimator(num_samples=1000)\n",
    "samples_conf_scores = 10\n",
    "model_module = cdmetadl.helpers.general_helpers.load_module_from_path(PROJECT_DIR / \"baselines/finetuning/model.py\")\n",
    "\n",
    "for T in (1, 10, 50, 100, 250, 500, 750, 1000, 1500, 2000):\n",
    "    learner = model_module.MyLearner()\n",
    "    learner.load(\"/fastdata/vilab25/output/final_a/training/dropout_k_5/finetuning/cross-domain/model\")\n",
    "    learner.T = T\n",
    "    conf_scores = np.array([confidence_estimator.estimate(learner, task.support_set)[1] for _ in tqdm(range(samples_conf_scores))])\n",
    "\n",
    "    correlation_between_conf_scores = np.corrcoef(conf_scores)\n",
    "\n",
    "    avg_correlation = (sum(np.corrcoef(conf_scores).flatten()) - samples_conf_scores)/(samples_conf_scores**2 - samples_conf_scores)\n",
    "    print(f\"T: {T}, Average Correlation between runs: {round(avg_correlation, 4)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ResNet' object has no attribute 'forward_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m learner\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m=\u001b[39m T\n\u001b[1;32m      9\u001b[0m samples_conf_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 10\u001b[0m conf_scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43m[\u001b[49m\u001b[43mconfidence_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_set\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msamples_conf_scores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     12\u001b[0m correlation_between_conf_scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcorrcoef(conf_scores)\n\u001b[1;32m     14\u001b[0m avg_correlation \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28msum\u001b[39m(np\u001b[38;5;241m.\u001b[39mcorrcoef(conf_scores)\u001b[38;5;241m.\u001b[39mflatten()) \u001b[38;5;241m-\u001b[39m samples_conf_scores)\u001b[38;5;241m/\u001b[39m(samples_conf_scores\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m samples_conf_scores)\n",
      "Cell \u001b[0;32mIn[17], line 10\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m learner\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m=\u001b[39m T\n\u001b[1;32m      9\u001b[0m samples_conf_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 10\u001b[0m conf_scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mconfidence_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_set\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(samples_conf_scores))])\n\u001b[1;32m     12\u001b[0m correlation_between_conf_scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcorrcoef(conf_scores)\n\u001b[1;32m     14\u001b[0m avg_correlation \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28msum\u001b[39m(np\u001b[38;5;241m.\u001b[39mcorrcoef(conf_scores)\u001b[38;5;241m.\u001b[39mflatten()) \u001b[38;5;241m-\u001b[39m samples_conf_scores)\u001b[38;5;241m/\u001b[39m(samples_conf_scores\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m samples_conf_scores)\n",
      "File \u001b[0;32m~/Confidence-based-generative-data-Augmentation-for-Meta-Learning/cdmetadl/confidence/mc_dropout_estimator.py:43\u001b[0m, in \u001b[0;36mMCDropoutConfidenceEstimator.estimate\u001b[0;34m(self, learner, data_set)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mestimate\u001b[39m(\u001b[38;5;28mself\u001b[39m, learner: cdmetadl\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mLearner,\n\u001b[1;32m     32\u001b[0m              data_set: cdmetadl\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mSetData) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[cdmetadl\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mSetData, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[1;32m     33\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    Generates a confidence score for each class in the given data set.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m        A tuple consisting of a dataset which can be used for finetuning the model and a list of confidence scores.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m \u001b[43mlearner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m predictor\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodules():\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDropout\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/Confidence-based-generative-data-Augmentation-for-Meta-Learning/baselines/maml/model.py:386\u001b[0m, in \u001b[0;36mMyLearner.fit\u001b[0;34m(self, support_set)\u001b[0m\n\u001b[1;32m    384\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msecond_order \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT):\n\u001b[0;32m--> 386\u001b[0m         grads \u001b[38;5;241m=\u001b[39m \u001b[43mget_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msecond_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m         task_weights \u001b[38;5;241m=\u001b[39m update_weights(task_weights, grads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_clip, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr)\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m MyPredictor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearner, task_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdev, prototypes)\n",
      "File \u001b[0;32m~/Confidence-based-generative-data-Augmentation-for-Meta-Learning/baselines/maml/helpers_maml.py:54\u001b[0m, in \u001b[0;36mget_grads\u001b[0;34m(model, X_train, y_train, weights, second_order, retain_graph)\u001b[0m\n\u001b[1;32m     52\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(X_train)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_weights\u001b[49m(X_train, weights)\n\u001b[1;32m     56\u001b[0m loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcriterion(out, y_train)\n\u001b[1;32m     57\u001b[0m grads \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(loss, weights, create_graph\u001b[38;5;241m=\u001b[39msecond_order, retain_graph\u001b[38;5;241m=\u001b[39mretain_graph)\n",
      "File \u001b[0;32m/fastdata/vilab25/cd-metadl-cyLvmR8c-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ResNet' object has no attribute 'forward_weights'"
     ]
    }
   ],
   "source": [
    "confidence_estimator = cdmetadl.confidence.MCDropoutConfidenceEstimator(num_samples=1000)\n",
    "samples_conf_scores = 10\n",
    "\n",
    "\n",
    "for T in (1, 5, 10, 20, 30, 50, 70, 100, 150, 200):\n",
    "    model_module = cdmetadl.helpers.general_helpers.load_module_from_path(PROJECT_DIR / \"baselines/maml/model.py\")\n",
    "    learner = model_module.MyLearner()\n",
    "    learner.load(\"/fastdata/vilab25/output/final_a/training/dropout_k_5/maml/cross-domain/model\")\n",
    "    learner.T = T\n",
    "    conf_scores = np.array([confidence_estimator.estimate(learner, task.support_set)[1] for _ in tqdm(range(samples_conf_scores))])\n",
    "\n",
    "    correlation_between_conf_scores = np.corrcoef(conf_scores)\n",
    "\n",
    "    avg_correlation = (sum(np.corrcoef(conf_scores).flatten()) - samples_conf_scores)/(samples_conf_scores**2 - samples_conf_scores)\n",
    "    print(f\"T: {T}, Average Correlation between runs: {round(avg_correlation, 4)}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
